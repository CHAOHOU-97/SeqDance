{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../model\")\n",
    "from config import config # please first download the dataset and fill in the config.py file with the path where you downloaded the dataset\n",
    "from model import ESMwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ESMwrap(\n",
       "  (esm2): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 480, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (position_embeddings): Embedding(1026, 480, padding_idx=1)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (pooler): EsmPooler(\n",
       "      (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear(in_features=240, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (res_pred_nn): Sequential(\n",
       "    (0): Linear(in_features=480, out_features=480, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=480, out_features=50, bias=True)\n",
       "  )\n",
       "  (res_transform_nn): Sequential(\n",
       "    (0): Linear(in_features=480, out_features=480, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=480, out_features=960, bias=True)\n",
       "  )\n",
       "  (pair_middle_linear): Linear(in_features=960, out_features=240, bias=True)\n",
       "  (pair_pred_linear): Linear(in_features=480, out_features=13, bias=True)\n",
       "  (gelu): GELU(approximate='none')\n",
       "  (softplus): Softplus(beta=1.0, threshold=2.0)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "\n",
    "# Load model\n",
    "esm2_select = 'model_35M'\n",
    "model_select = 'seqdance' # or 'esmdance'\n",
    "dance_model = ESMwrap(esm2_select, model_select).to(device)\n",
    "\n",
    "# Load the SeqDance model from huggingface\n",
    "dance_model = dance_model.from_pretrained(\"ChaoHou/ESMDance\")\n",
    "dance_model = dance_model.to(device)\n",
    "dance_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset, use test set\n",
    "df = pd.read_csv(config['file_path']['train_df_path'])\n",
    "df = df[df['label'] == 'test']\n",
    "\n",
    "# Load HDF5 dataset\n",
    "h5py_read = h5py.File(config['file_path']['h5py_path'], 'r')\n",
    "max_len = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"/nfs/user/Users/ch3849/ProDance/data_new/seq/name_seq_all_mdCATH_ATLAS_GPCRmd_PED_IDRome_proteinflow.csv\")\n",
    "df = df[df['label'] == 'test']\n",
    "\n",
    "# Load HDF5 dataset\n",
    "h5py_read = h5py.File(\"/ssd/Users/ch3849/prodance/feature_all_mdCATH_ATLAS_GPCRmd_PED_IDRome_proteinflow.h5\", 'r')\n",
    "max_len = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get pariwise dynamic properties with 240 SeqDance attention maps\n",
    "using 1a0aA00 from mdCATH as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sequence and pair feature of the protein\n",
    "pro = '1a0aA00'\n",
    "seq = df[df['name'] == pro]['modify_seq'].values[0]\n",
    "pair_f = h5py_read[f'{pro}_pair_feature'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the sequence, for longer sequences, we need to truncate them to the max length\n",
    "raw_input = tokenizer(seq, return_tensors=\"pt\", max_length=max_len, truncation=True)\n",
    "length = raw_input['input_ids'].shape[1]\n",
    "pair_f = pair_f[:length, :length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the attention map\n",
    "with torch.no_grad():\n",
    "    output = dance_model(raw_input.to(device), return_attention_map=True)\n",
    "atten = output['attention_map'][0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 (65, 65, 240) (65, 65, 10)\n"
     ]
    }
   ],
   "source": [
    "print(length, atten.shape, pair_f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare pariwise dynamic properties with 240 SeqDance attention maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only analyze residues with distance > 2\n",
    "row_indices, col_indices = np.where(np.abs(np.arange(length)[:, None] - np.arange(length)) > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_move = pair_f[:,:,9]\n",
    "inter = (pair_f[:,:,:9]**3).sum(-1) # the interaction frequency is pow(x, 1/3) in the file, as we use this value to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "atten_scores = {'co_move_topL_ratio': [], 'co_move_posi_spearman': [], 'co_move_neg_spearman': [], 'inter_topL_ratio': [], 'inter_auroc': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for movement corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = co_move[row_indices, col_indices]\n",
    "mask = f != -1 # -1 is padding\n",
    "f_flat = f[mask]\n",
    "\n",
    "for k in range(atten.shape[-1]):\n",
    "    att = atten[:, :, k][row_indices, col_indices]\n",
    "    att_flat = att[mask]\n",
    "\n",
    "    # Compute fold change\n",
    "    top_L_indices = np.argsort(-att_flat)[:length]  # Negative sign for descending sort\n",
    "    top_L_mean = np.mean(np.abs(f_flat[top_L_indices]))\n",
    "    other_indices = np.setdiff1d(np.arange(f_flat.shape[0]), top_L_indices)\n",
    "    other_mean = np.mean(np.abs(f_flat[other_indices]))\n",
    "\n",
    "    atten_scores['co_move_topL_ratio'].append(top_L_mean / (other_mean + 1e-8))\n",
    "\n",
    "    # Compute Spearman correlations\n",
    "    atten_scores['co_move_posi_spearman'].append(spearmanr(att_flat[f_flat > 0], f_flat[f_flat > 0])[0])\n",
    "    atten_scores['co_move_neg_spearman'].append(spearmanr(att_flat[f_flat < 0], f_flat[f_flat < 0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for summed interaction frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = inter[row_indices, col_indices]\n",
    "# for fold change\n",
    "mask = f != -9 # -9 is summed padding of 9 interactions\n",
    "f_flat = f[mask]\n",
    "\n",
    "# for AUROC\n",
    "mask_auroc = mask = (f == 0) | (f >= 0.01) # for binary classification, positive are interaction frequency > 0.01\n",
    "f_auroc = f[mask_auroc]\n",
    "f_binary = f_auroc > 0\n",
    "\n",
    "for k in range(atten.shape[-1]):\n",
    "    att = atten[:, :, k][row_indices, col_indices]\n",
    "    att_flat = att[mask]\n",
    "\n",
    "    # Compute fold change\n",
    "    top_L_indices = np.argsort(-att_flat)[:length]  # Negative sign for descending sort\n",
    "    top_L_mean = np.mean(np.abs(f_flat[top_L_indices]))\n",
    "    other_indices = np.setdiff1d(np.arange(f_flat.shape[0]), top_L_indices)\n",
    "    other_mean = np.mean(np.abs(f_flat[other_indices]))\n",
    "\n",
    "    atten_scores['inter_topL_ratio'].append(top_L_mean / (other_mean + 1e-8))\n",
    "\n",
    "    # Compute AUROC\n",
    "    att_auroc = att[mask_auroc]\n",
    "    atten_scores['inter_auroc'].append(roc_auc_score(f_binary, att_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co_move_topL_ratio</th>\n",
       "      <th>co_move_posi_spearman</th>\n",
       "      <th>co_move_neg_spearman</th>\n",
       "      <th>inter_topL_ratio</th>\n",
       "      <th>inter_auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.444880</td>\n",
       "      <td>0.231459</td>\n",
       "      <td>-0.009377</td>\n",
       "      <td>1.091253</td>\n",
       "      <td>0.513889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.595649</td>\n",
       "      <td>0.217605</td>\n",
       "      <td>0.077245</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.042282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.597570</td>\n",
       "      <td>-0.279531</td>\n",
       "      <td>-0.212586</td>\n",
       "      <td>0.076810</td>\n",
       "      <td>0.340415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.023115</td>\n",
       "      <td>0.057276</td>\n",
       "      <td>-0.053536</td>\n",
       "      <td>0.647623</td>\n",
       "      <td>0.489946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.200960</td>\n",
       "      <td>0.213669</td>\n",
       "      <td>-0.012227</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>0.516420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.706290</td>\n",
       "      <td>0.414706</td>\n",
       "      <td>0.042398</td>\n",
       "      <td>1.422613</td>\n",
       "      <td>0.536317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.103030</td>\n",
       "      <td>0.715159</td>\n",
       "      <td>0.240129</td>\n",
       "      <td>3.477425</td>\n",
       "      <td>0.645985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       co_move_topL_ratio  co_move_posi_spearman  co_move_neg_spearman  \\\n",
       "count          240.000000             240.000000            240.000000   \n",
       "mean             1.444880               0.231459             -0.009377   \n",
       "std              0.595649               0.217605              0.077245   \n",
       "min              0.597570              -0.279531             -0.212586   \n",
       "25%              1.023115               0.057276             -0.053536   \n",
       "50%              1.200960               0.213669             -0.012227   \n",
       "75%              1.706290               0.414706              0.042398   \n",
       "max              3.103030               0.715159              0.240129   \n",
       "\n",
       "       inter_topL_ratio  inter_auroc  \n",
       "count        240.000000   240.000000  \n",
       "mean           1.091253     0.513889  \n",
       "std            0.653905     0.042282  \n",
       "min            0.076810     0.340415  \n",
       "25%            0.647623     0.489946  \n",
       "50%            0.941406     0.516420  \n",
       "75%            1.422613     0.536317  \n",
       "max            3.477425     0.645985  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_atten_scores = pd.DataFrame(atten_scores)\n",
    "df_atten_scores.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
